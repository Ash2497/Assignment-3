{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84380311",
      "metadata": {
        "id": "84380311"
      },
      "outputs": [],
      "source": [
        "#RNN with attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1537eb9e",
      "metadata": {
        "id": "1537eb9e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential,Model,load_model\n",
        "from keras.layers import Dense,LSTM,GRU,SimpleRNN,Input,Dropout,TimeDistributed,RepeatVector,dot,BatchNormalization,concatenate,multiply,Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Layer\n",
        "from keras.preprocessing import sequence\n",
        "# updated as tensorflow.keras\n",
        "from tensorflow.keras.optimizers import Adam,Adadelta,Nadam,SGD\n",
        "from keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d96f645",
      "metadata": {
        "id": "5d96f645"
      },
      "outputs": [],
      "source": [
        "class AttentionModel(Layer):\n",
        "  def __init__(self, units):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "    \n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "    \n",
        "    attention_wts = tf.nn.softmax(score, axis=1)\n",
        "    context_vector = tf.reduce_sum((attention_wts * values), axis=1)\n",
        "\n",
        "    return context_vector, attention_wts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20b5032a",
      "metadata": {
        "id": "20b5032a"
      },
      "outputs": [],
      "source": [
        "class Encoder(Model):\n",
        "  def __init__(self,cell,vocab_size, embedding_dim, latent_dim, batch_size,initializer,dropouts):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.cell = cell\n",
        "    self.batch_size = batch_size\n",
        "    self.latent_dim = latent_dim\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim)\n",
        "    if cell == \"gru\":\n",
        "        self.gru = GRU(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "    elif cell == \"lstm\":\n",
        "        self.lstm = LSTM(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "    elif cell == \"rnn\":\n",
        "        self.rnn = SimpleRNN(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    if self.cell == \"gru\":\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "    elif self.cell == \"lstm\":\n",
        "        output, state, state_c= self.lstm(x, initial_state=hidden)\n",
        "    elif self.cell == \"rnn\":\n",
        "        output, state = self.rnn(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def init_hidden_state(self):\n",
        "      if self.cell == 'lstm':\n",
        "          return [tf.zeros((self.batch_size, self.latent_dim)),tf.zeros((self.batch_size, self.latent_dim))]\n",
        "      return tf.zeros((self.batch_size, self.latent_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fabed88d",
      "metadata": {
        "id": "fabed88d"
      },
      "outputs": [],
      "source": [
        "class Decoder(Model):\n",
        "  def __init__(self, cell, vocab_size, embedding_dim, latent_dim, batch_size,initializer,dropouts):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.cell = cell\n",
        "    self.batch_size = batch_size\n",
        "    self.attention = AttentionModel(latent_dim)\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim)\n",
        "    self.dense = Dense(vocab_size)\n",
        "    if cell == \"gru\":\n",
        "        self.gru = GRU(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "    elif cell == \"lstm\":\n",
        "        self.lstm = LSTM(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "    elif cell == \"rnn\":\n",
        "        self.rnn = SimpleRNN(latent_dim,return_sequences=True,return_state=True,recurrent_initializer = initializer,dropout=dropouts)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    x = self.embedding(x)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "    if self.cell == \"gru\":\n",
        "        output, state = self.gru(x)\n",
        "    elif self.cell == \"lstm\":\n",
        "        output, state,state_c = self.lstm(x)\n",
        "    elif self.cell == \"rnn\":\n",
        "        output, state = self.rnn(x)\n",
        "\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "    x = self.dense(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a103015",
      "metadata": {
        "id": "1a103015"
      },
      "outputs": [],
      "source": [
        "class Attention:\n",
        "    def __init__(self,cell,embedding_size,latent_dim,optimizer,dropouts,batch_size,epochs,initializer):\n",
        "        self.cell = cell\n",
        "        self.embedding_dim = embedding_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.BATCH_SIZE = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.opt = optimizer\n",
        "        self.dropouts=dropouts\n",
        "        self.initializer=initializer\n",
        "\n",
        "    @tf.function()    \n",
        "    def train_step_wise(self, inp, targ, enc_hidden):\n",
        "        loss = 0\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
        "            dec_hidden = enc_hidden\n",
        "            dec_input = tf.expand_dims([self.input_token_index['\\t']] * self.BATCH_SIZE, 1)\n",
        "\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
        "                loss += self.calculate_loss(targ[:, t], predictions)\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        variables = self.encoder.trainable_variables + self.decoder.trainable_variables + self.decoder.attention.trainable_variables\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "        return batch_loss\n",
        "\n",
        "    def get_data(self,path):\n",
        "        d = pd.read_csv(path,sep=\"\\t\",header=None,error_bad_lines=False)\n",
        "        d = d.dropna()\n",
        "\n",
        "        decoder_target_data = np.zeros((d.shape[0],self.max_length_y,self.decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "        for i,target_text in enumerate(d[0]):\n",
        "            target_text = '\\t'+target_text+'\\n'\n",
        "            for t, char in enumerate(target_text):\n",
        "                if t > 0:\n",
        "                    decoder_target_data[i, t - 1, self.target_token_index[char]] = 1.0\n",
        "            decoder_target_data[i, t:, self.target_token_index[\"\\n\"]] = 1.0\n",
        "\n",
        "        return ([[self.input_token_index[letter] for letter in list('\\t'+word+'\\n')] for word in d[1]]),\\\n",
        "                ([[self.target_token_index[letter] for letter in list('\\t'+word+'\\n')] for word in d[0]]),decoder_target_data\n",
        "\n",
        "    def create_vocabulary(self,path):\n",
        "        d = pd.read_csv(path,sep=\"\\t\",header=None,error_bad_lines=False)\n",
        "        d = d.dropna()\n",
        "\n",
        "        x = [list('\\t'+word+'\\n') for word in np.array(d[1])]\n",
        "        y = [list('\\t'+word+'\\n') for word in np.array(d[0])]\n",
        "\n",
        "        tamil_vocabulary = set()\n",
        "        english_vocab = set()\n",
        "\n",
        "        for word in x:\n",
        "            for char in word:\n",
        "                english_vocab.add(char)\n",
        "\n",
        "        for word in y:\n",
        "            for char in word:\n",
        "                tamil_vocabulary.add(char)\n",
        "\n",
        "        tamil_list = sorted(list(tamil_vocabulary))\n",
        "        english_list = sorted(list(english_vocab))\n",
        "\n",
        "        max_length_x = (np.max([len(i) for i in x]))\n",
        "        max_length_y = (np.max([len(i) for i in y]))\n",
        "\n",
        "        return tamil_list,english_list,max_length_x,max_length_y    \n",
        "\n",
        "    def create_data(self):\n",
        "        train_path = \"/home/catlab/RNN/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\"\n",
        "        cv_path = \"/home/catlab/RNN/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\"\n",
        "        test_path = \"/home/catlab/RNN/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\"\n",
        "\n",
        "        tamil_list,english_list,self.max_length_x,self.max_length_y = self.create_vocabulary(train_path)\n",
        "        self.encoder_tokens = len(english_list)\n",
        "        self.decoder_tokens = len(tamil_list)\n",
        "\n",
        "        # Dict for char to index\n",
        "        self.input_token_index = dict([(char, i) for i, char in enumerate(english_list)])\n",
        "        self.target_token_index = dict([(char, i) for i, char in enumerate(tamil_list)])\n",
        "\n",
        "        # Dict for index to char\n",
        "        self.inv_input_token_index = dict({(value,key) for key,value in self.input_token_index.items()})\n",
        "        self.inv_target_token_index = dict({(value,key) for key,value in self.target_token_index.items()})\n",
        "\n",
        "        encoder_train,decoder_train,self.decoder_target_train = self.get_data(train_path)\n",
        "        encoder_cv,decoder_cv,self.decoder_target_cv = self.get_data(cv_path)\n",
        "        encoder_test,decoder_test,self.decoder_target_test = self.get_data(test_path)\n",
        "\n",
        "\n",
        "        self.encoder_train = sequence.pad_sequences(encoder_train,maxlen=self.max_length_x,padding=\"post\")\n",
        "        self.decoder_train = sequence.pad_sequences(decoder_train,maxlen=self.max_length_y,padding=\"post\")\n",
        "        self.encoder_cv = sequence.pad_sequences(encoder_cv,maxlen=self.max_length_x,padding=\"post\")\n",
        "        self.decoder_cv = sequence.pad_sequences(decoder_cv,maxlen=self.max_length_y,padding=\"post\")\n",
        "        self.encoder_test = sequence.pad_sequences(encoder_test,maxlen=self.max_length_x,padding=\"post\")\n",
        "        self.decoder_test = sequence.pad_sequences(decoder_test,maxlen=self.max_length_y,padding=\"post\")\n",
        "\n",
        "        self.BUFFER_SIZE = len(self.encoder_train)        \n",
        "        self.steps_per_epoch = len(self.encoder_train)//self.BATCH_SIZE\n",
        "\n",
        "        self.dataset = tf.data.Dataset.from_tensor_slices((self.encoder_train, self.decoder_train)).shuffle(self.BUFFER_SIZE)\n",
        "        self.dataset = self.dataset.batch(self.BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "\n",
        "    def calculate_loss(self,real, pred):\n",
        "        mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "        loss_ = self.loss_object(real, pred)\n",
        "        loss_ *= tf.cast(mask, dtype=loss_.dtype)\n",
        "\n",
        "        return tf.reduce_mean(loss_)\n",
        "\n",
        "    def run(self):\n",
        "        # Compile & run training\n",
        "        if self.opt == \"nadam\":\n",
        "            self.optimizer = Nadam()\n",
        "        elif self.opt == \"sgd\":\n",
        "            self.optimizer = SGD()\n",
        "        elif self.opt == \"adadelta\":\n",
        "            self.optimizer = Adadelta()\n",
        "        else:\n",
        "            self.optimizer = Adam()\n",
        "\n",
        "        self.loss_object = SparseCategoricalCrossentropy(from_logits=True,reduction='none')\n",
        "        \n",
        "        self.encoder = Encoder(self.cell,self.encoder_tokens, self.embedding_dim, self.latent_dim, self.BATCH_SIZE, self.initializer,self.dropouts)\n",
        "        self.decoder = Decoder(self.cell,self.decoder_tokens, self.embedding_dim, self.latent_dim, self.BATCH_SIZE, self.initializer,self.dropouts)\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            enc_hidden = self.encoder.init_hidden_state()\n",
        "            total_loss = 0\n",
        "            \n",
        "            for (batch, (inp, targ)) in enumerate(self.dataset.take(self.steps_per_epoch)):\n",
        "                batch_loss = self.train_step_wise(inp, targ, enc_hidden)\n",
        "                total_loss += batch_loss \n",
        "\n",
        "            print(f'Epoch {epoch+1} Loss {total_loss/self.steps_per_epoch:.4f}   ')        \n",
        "\n",
        "\n",
        "    def evaluate_model(self,sentence_vect,attention=False):\n",
        "        if attention:\n",
        "            att_plot = np.zeros((self.max_length_y,self.max_length_x))\n",
        "        inputs = tf.convert_to_tensor(sentence_vect)\n",
        "        inputs = tf.expand_dims(inputs,0)\n",
        "        result = ''\n",
        "        if self.cell == \"lstm\":\n",
        "            hidden = [tf.zeros((1, self.latent_dim)),tf.zeros((1, self.latent_dim))]\n",
        "        else:\n",
        "            hidden = [tf.zeros((1, self.latent_dim))]\n",
        "        enc_out, enc_hidden = self.encoder(inputs, hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([self.target_token_index['\\t']], 0)\n",
        "\n",
        "        for t in range(self.max_length_y):\n",
        "            predictions, dec_hidden, attention_weights = self.decoder(dec_input, dec_hidden, enc_out)\n",
        "            \n",
        "            if attention:\n",
        "                att_plot[t] = (tf.reshape(attention_weights,(-1,))).numpy()\n",
        "\n",
        "            predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "            if self.inv_target_token_index[predicted_id] != \"\\n\":\n",
        "                result += self.inv_target_token_index[predicted_id]\n",
        "            else:\n",
        "                if attention:\n",
        "                    return result,att_plot\n",
        "                return result\n",
        "\n",
        "            dec_input = tf.expand_dims([predicted_id], 0) \n",
        "\n",
        "        if attention:\n",
        "            return result,att_plot\n",
        "        return result\n",
        "\n",
        "    def test_predictions_accuracy(self):\n",
        "        count = 0\n",
        "        for i in range(len(self.decoder_test)):\n",
        "            actual = \"\"\n",
        "            for x in self.decoder_test[i][1:]:\n",
        "                if self.inv_target_token_index[x]==\"\\n\":\n",
        "                    break\n",
        "                actual += self.inv_target_token_index[x]\n",
        "\n",
        "            pred = self.evaluate_model(self.encoder_test[i])\n",
        "            if (actual==pred):\n",
        "                count+=1\n",
        "                \n",
        "        return count/len(self.decoder_test)\n",
        "\n",
        "    def cv_predictions_accuracy(self):\n",
        "        count = 0\n",
        "        for i in range(len(self.decoder_cv)):\n",
        "            actual = \"\"\n",
        "            for x in self.decoder_cv[i][1:]:\n",
        "                if self.inv_target_token_index[x]==\"\\n\":\n",
        "                    break\n",
        "                actual += self.inv_target_token_index[x]\n",
        "\n",
        "            pred = self.evaluate_model(self.encoder_cv[i])\n",
        "            if (actual==pred):\n",
        "                count+=1\n",
        "\n",
        "        return count/len(self.decoder_cv)\n",
        "    \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f6b02cb",
      "metadata": {
        "id": "0f6b02cb"
      },
      "outputs": [],
      "source": [
        "#setting up wandb sweeps\n",
        "sweep_config={\n",
        "    'method': 'random',\n",
        "    'metric': {\n",
        "        'name': 'accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters':{\n",
        "        'epochs':{\n",
        "            'values':[3,5,6]\n",
        "        },\n",
        "        'embedding_size':{\n",
        "            'values':[8,12,16]\n",
        "        },\n",
        "        'cell':{\n",
        "            'values':[\"gru\",\"lstm\",\"rnn\"]\n",
        "        },\n",
        "        'dropouts':{\n",
        "            'values':[0,0.2,0.3]\n",
        "        },\n",
        "        'latent_dim':{\n",
        "            'values':[32,128,256,512]\n",
        "        },\n",
        "        'batch_size':{\n",
        "            'values':[32,64]\n",
        "        },\n",
        "        'optimizers':{\n",
        "            'values':[\"nadam\",\"adam\",\"sgd\"]\n",
        "        },\n",
        "       'initializer':{\n",
        "            'values':[\"orthogonal\",\"glorot_uniform\"]\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b8502ed",
      "metadata": {
        "id": "6b8502ed",
        "outputId": "4a974689-6104-4324-a904-6a638f987afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mas1_dl\u001b[0m (use `wandb login --relogin` to force relogin)\r\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "!wandb login \n",
        "#key if required\n",
        "#17cea20df689f25f619d7fbaa771206983675111"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e63d247",
      "metadata": {
        "id": "3e63d247",
        "outputId": "559e9668-4475-4bc0-845e-b7acdbb9dc4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: nvuzrccz\n",
            "Sweep URL: https://wandb.ai/as1_dl/AttnSweeps/sweeps/nvuzrccz\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config,project=\"AttnSweeps\", entity=\"as1_dl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab0c4cc2",
      "metadata": {
        "id": "ab0c4cc2"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    config_defaults={\n",
        "      'epochs':5,\n",
        "      'embedding_size':16,\n",
        "      'dropouts':0.3,\n",
        "      'optimizers':\"adam\",\n",
        "      'cell':\"lstm\",\n",
        "      'latent_dim':512,\n",
        "      'batch_size': 64,\n",
        "      'initializer':\"glorot_uniform\"\n",
        "       }\n",
        "    \n",
        "    wandb.init(config=config_defaults)\n",
        "    config=wandb.config\n",
        "    seqatt=Attention(config.cell,config.embedding_size,config.latent_dim,config.optimizers,config.dropouts,config.batch_size,config.epochs,config.initializer)\n",
        "    seqatt.create_data()\n",
        "    seqatt.run()\n",
        "    val_acc=seqatt.cv_predictions_accuracy()\n",
        "    wandb.log({'validation accuracy':val_acc})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f93acef0",
      "metadata": {
        "id": "f93acef0",
        "outputId": "b619d48f-0215-4325-89c6-757f41202292",
        "colab": {
          "referenced_widgets": [
            ""
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9vveahye with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: lstm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropouts: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitializer: glorot_uniform\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizers: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mas1_dl\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/as1_dl/AttnSweeps/runs/9vveahye\" target=\"_blank\">genial-sweep-1</a></strong> to <a href=\"https://wandb.ai/as1_dl/AttnSweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/as1_dl/AttnSweeps/sweeps/nvuzrccz\" target=\"_blank\">https://wandb.ai/as1_dl/AttnSweeps/sweeps/nvuzrccz</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_7712/3073565139.py:78: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  tamil_list,english_list,self.max_length_x,self.max_length_y = self.create_vocabulary(train_path)\n",
            "/tmp/ipykernel_7712/3073565139.py:90: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  encoder_train,decoder_train,self.decoder_target_train = self.get_data(train_path)\n",
            "/tmp/ipykernel_7712/3073565139.py:91: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  encoder_cv,decoder_cv,self.decoder_target_cv = self.get_data(cv_path)\n",
            "/tmp/ipykernel_7712/3073565139.py:92: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  encoder_test,decoder_test,self.decoder_target_test = self.get_data(test_path)\n",
            "2022-05-08 18:34:34.746114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-08 18:34:34.756145: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda-11.2/lib64\n",
            "2022-05-08 18:34:34.756164: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2022-05-08 18:34:34.756779: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.7685   \n",
            "Epoch 2 Loss 0.4315   \n",
            "Epoch 3 Loss 0.1983   \n",
            "Epoch 4 Loss 0.1505   \n",
            "Epoch 5 Loss 0.1335   \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 7775... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validation accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validation accuracy</td><td>0.50491</td></tr></table>\n",
              "</div></div>\n",
              "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">genial-sweep-1</strong>: <a href=\"https://wandb.ai/as1_dl/AttnSweeps/runs/9vveahye\" target=\"_blank\">https://wandb.ai/as1_dl/AttnSweeps/runs/9vveahye</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220508_183426-9vveahye/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gz79hq3u with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: rnn\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropouts: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 12\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitializer: glorot_uniform\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizers: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/as1_dl/AttnSweeps/runs/gz79hq3u\" target=\"_blank\">devoted-sweep-2</a></strong> to <a href=\"https://wandb.ai/as1_dl/AttnSweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/as1_dl/AttnSweeps/sweeps/nvuzrccz\" target=\"_blank\">https://wandb.ai/as1_dl/AttnSweeps/sweeps/nvuzrccz</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.9299   \n",
            "Epoch 2 Loss 0.8256   \n",
            "Epoch 3 Loss 0.7766   \n",
            "Epoch 4 Loss 0.7479   \n",
            "Epoch 5 Loss 0.7260   \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 8438... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>validation accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>validation accuracy</td><td>0.0</td></tr></table>\n",
              "</div></div>\n",
              "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">devoted-sweep-2</strong>: <a href=\"https://wandb.ai/as1_dl/AttnSweeps/runs/gz79hq3u\" target=\"_blank\">https://wandb.ai/as1_dl/AttnSweeps/runs/gz79hq3u</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220508_185100-gz79hq3u/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ld1ioju2 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropouts: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitializer: orthogonal\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizers: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/as1_dl/AttnSweeps/runs/ld1ioju2\" target=\"_blank\">cool-sweep-3</a></strong> to <a href=\"https://wandb.ai/as1_dl/AttnSweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/as1_dl/AttnSweeps/sweeps/nvuzrccz\" target=\"_blank\">https://wandb.ai/as1_dl/AttnSweeps/sweeps/nvuzrccz</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ],
      "source": [
        "wandb.agent(sweep_id,train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69151876",
      "metadata": {
        "id": "69151876",
        "outputId": "22dae687-9f15-4ead-a87c-a472a7749a32",
        "colab": {
          "referenced_widgets": [
            ""
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_7712/3073565139.py:78: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  tamil_list,english_list,self.max_length_x,self.max_length_y = self.create_vocabulary(train_path)\n",
            "/tmp/ipykernel_7712/3073565139.py:90: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  encoder_train,decoder_train,self.decoder_target_train = self.get_data(train_path)\n",
            "/tmp/ipykernel_7712/3073565139.py:91: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  encoder_cv,decoder_cv,self.decoder_target_cv = self.get_data(cv_path)\n",
            "/tmp/ipykernel_7712/3073565139.py:92: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  encoder_test,decoder_test,self.decoder_target_test = self.get_data(test_path)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 9311... <strong style=\"color:red\">(failed 1).</strong> Press ctrl-c to abort syncing."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "</div><div class=\"wandb-col\">\n",
              "</div></div>\n",
              "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">cool-sweep-3</strong>: <a href=\"https://wandb.ai/as1_dl/AttnSweeps/runs/ld1ioju2\" target=\"_blank\">https://wandb.ai/as1_dl/AttnSweeps/runs/ld1ioju2</a><br/>\n",
              "Find logs at: <code>./wandb/run-20220508_190951-ld1ioju2/logs</code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.5357   \n",
            "Epoch 2 Loss 0.1603   \n",
            "Epoch 3 Loss 0.1213   \n",
            "Epoch 4 Loss 0.1158   \n",
            "Epoch 5 Loss 0.1021   \n",
            "Epoch 6 Loss 0.0927   \n"
          ]
        }
      ],
      "source": [
        "#Best model specs\n",
        "\n",
        "# val accuracy: 56 \n",
        "# batch_size: 32\n",
        "# wandb: \tcell: gru\n",
        "# wandb: \tdropouts: 0.2\n",
        "# wandb: \tembedding_size: 16\n",
        "# wandb: \tepochs: 6\n",
        "# wandb: \tinitializer: glorot_uniform\n",
        "# wandb: \tlatent_dim: 256\n",
        "# wandb: \toptimizers: nadam\n",
        "\n",
        "\n",
        "\n",
        "seqatt = Attention(\"gru\",16,256,\"nadam\",0.2,32,6,\"glorot_uniform\")\n",
        "seqatt.create_data()\n",
        "seqatt.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aab9ca8",
      "metadata": {
        "id": "9aab9ca8",
        "outputId": "faecff78-220d-4cd3-dbbf-0b2c2cf93e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross Validation Word Accuracy is 52.277720814413364\n"
          ]
        }
      ],
      "source": [
        "cv_acc = seqatt.cv_predictions_accuracy()\n",
        "print(\"Cross Validation Word Accuracy is\",cv_acc*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8deecb1",
      "metadata": {
        "id": "a8deecb1",
        "outputId": "b3c762bf-7fbb-4fe0-beeb-80d0fee32910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Word Accuracy is 50.189393939393945\n"
          ]
        }
      ],
      "source": [
        "test_acc = seqatt.test_predictions_accuracy()\n",
        "\n",
        "print(\"Test Word Accuracy is\",test_acc*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2563c1",
      "metadata": {
        "scrolled": false,
        "id": "3c2563c1",
        "outputId": "e0a91960-521d-4dd8-ce37-c4cfb75be56b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['faarm', 'farm', 'form', 'hpaarm', 'face']\n",
            "['ஃபார்ம்', 'ஃபார்ம்', 'ஃபார்ம்', 'ஃபார்ம்', 'ஃபேஸ்']\n",
            "['பார்ம்', 'பர்ம்', 'போர்ம்', 'அப்பார்', 'பேசி']\n"
          ]
        }
      ],
      "source": [
        "pred_l,actual_l,input_l = [],[],[]\n",
        "\n",
        "for i in range(len(seqatt.decoder_test)):\n",
        "  input = \"\"\n",
        "  actual = \"\"\n",
        "  for x in seqatt.encoder_test[i][1:]:\n",
        "    if seqatt.inv_input_token_index[x]==\"\\n\":\n",
        "      break\n",
        "    input += seqatt.inv_input_token_index[x]\n",
        "\n",
        "  for x in seqatt.decoder_test[i][1:]:\n",
        "    if seqatt.inv_target_token_index[x]==\"\\n\":\n",
        "      break\n",
        "    actual += seqatt.inv_target_token_index[x]\n",
        "\n",
        "  pred = seqatt.evaluate_model(seqatt.encoder_test[i])\n",
        "\n",
        "  input_l.append(input)\n",
        "  actual_l.append(actual)\n",
        "  pred_l.append(pred)  \n",
        "print(input_l[:5])\n",
        "print(actual_l[:5])\n",
        "print(pred_l[:5])\n",
        "\n",
        "input_l = pd.Series(input_l)\n",
        "actual_l = pd.Series(actual_l)\n",
        "pred_l = pd.Series(pred_l)\n",
        "\n",
        "df = pd.concat((input_l,actual_l,pred_l),axis=1)\n",
        "df.columns = [\"Actual_Input\",\"Actual_Output\",\"Predicted_Output\"]\n",
        "df.to_csv(\"predictions_attention.csv\",index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92532e8f",
      "metadata": {
        "id": "92532e8f",
        "outputId": "762f31b1-87d9-4b95-c954-9163ec06d264"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mas1_dl\u001b[0m (use `wandb login --relogin` to force relogin)\r\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/as1_dl/AttnSweeps/runs/ld1ioju2\" target=\"_blank\">cool-sweep-3</a></strong> to <a href=\"https://wandb.ai/as1_dl/AttnSweeps\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "Sweep page: <a href=\"https://wandb.ai/as1_dl/AttnSweeps/sweeps/nvuzrccz\" target=\"_blank\">https://wandb.ai/as1_dl/AttnSweeps/sweeps/nvuzrccz</a><br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/as1_dl/AttnSweeps/runs/ld1ioju2?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f3dc31679a0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Attention plots\n",
        "import wandb\n",
        "!wandb login \n",
        "from wandb.keras import WandbCallback\n",
        "wandb.init(project=\"AttnSweeps\", entity=\"as1_dl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51dcb459",
      "metadata": {
        "id": "51dcb459",
        "outputId": "aecae821-ce1b-41f6-961c-8b22bd5c32fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2965 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 3009 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2993 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2965 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 3009 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2993 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2986 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2997 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 3007 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2991 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 3008 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2992 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 3021 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2986 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2997 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 3007 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2991 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 3008 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2992 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 3021 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAEvCAYAAAAkUlb5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAALhElEQVR4nO3db4ylZ1kG8OueTre77hYNJYV0hbZGJSC2UNqYSok2GlFDYiS1iJjAF5tYE2livxgIf2OI0Q/oByuNGlAQVIxfIEKVQLTVKrUtuoVGjJY/LTSxLbXbLm535/HDnMSh2ZmdnXnf7sw9v1/SZCZz5prn9Jxzzfu85925a4wRgC6WzvYCAKak1IBWlBrQilIDWlFqQCtKDWhlec7wAwcunuV6kXOXzpk88+Hffd3kmT/01jsmz0ySLzz6lVly57A8w2N1cuXk5JlJ4uKm3ePE8Qdrva85UgNaUWpAK0oNaEWpAa0oNaAVpQa0otSAVpQa0MppL76tqrev96UkY4zx7mmXBLB1m/kXBS8bY1x/qi9U1Z9PvB6AbZl8+1lVN1TVXVV114kTR6eOB9jQ5KU2xrh1jHHlGOPK5eVDU8cDbMgbBUArSg1oZTOltu6f+DjN1wCedZt59/PIOpd1VJIjE68HYFtOW2pjjHc9GwsBmIJzakArSg1oRakBrSg1oBWlBrRSY8w3GGx53+E9PXXs2Nc+O0vuwRdeO3nmyozPA5iaEXnAnqHUgFaUGtCKUgNaUWpAK0oNaEWpAa2YJgW0YpoU0IrtJ9DKrCPyVlaenDoeYEOzjshbWjo4dTzAhmw/gVZMkwJaMU0KaMU0KaAV59SAVpQa0IpSA1pRakArSg1oxTSpXejYQ38/eeaBi149eSbMxTQpYM9QakArSg1oRakBrSg1oBWlBrSi1IBWlBrQihF5QCtG5AGt2H4CrRiRB7RiRB7Qiu0n0IoReUArRuQBrRiRB7TinBrQilIDWlFqQCtKDWhFqQGtbOaSDrZo//K+WXJf9L2vnTzz6O3vmzwzSQ5dc9MsubAeR2pAK0oNaEWpAa0oNaAVpQa0otSAVpQa0IppUkArpkkBrdh+Aq2YJgW0YpoU0IrtJ9CKaVJAK6ZJAa2YJgW04pwa0IpSA1pRakArSg1oRakBrSg1oJUaY8wWfu6+w7OEz7dipvbUA7dNnnno0tdMnpkkKzO+FpjWieMPrnvhvyM1oBWlBrSi1IBWlBrQilIDWlFqQCtKDWjFiDygFSPygFZsP4FWjMgDWjEiD2jF9hNoxYg8oBUj8oBWjMgDWnFODWhFqQGtKDWgFaUGtKLUgFZmnSZ18QWXzRL+8JPfnDzzxMrJyTNJlmr6Sxnf+/wfnTwzSa5++tjkmT/71H2TZybJI8eemCV3tzBNCtgzlBrQilIDWlFqQCtKDWhFqQGtKDWgFaUGtGJEHtCKEXlAK7afQCuzjsg7+q1Hp44H2NCsI/IO7X/u1PEAG7L9BFoxIg9oxYg8oBUj8oBWnFMDWlFqQCtKDWhFqQGtKDWglVlH5C3vOzxfOLvCHCPy9i/vmzwzSZ534Dsnz7z3Z543eWaS/MLfTP//4JPfuHfyzLkYkQfsGUoNaEWpAa0oNaAVpQa0otSAVpQa0IppUkArpkkBrdh+Aq3MOk1qZeXJqeMBNjTrNKmlpYNTxwNsyPYTaMU0KaAV06SAVkyTAlpxTg1oRakBrSg1oBWlBrSi1IBWlBrQihF57DpzXfE9x5P1vOVzZ0hNHjsy/R/IOfSS102emSQrM3SMEXnAnqHUgFaUGtCKUgNaUWpAK0oNaEWpAa0YkQe0YkQe0IrtJ9CKEXlAK0bkAa3YfgKtGJEHtGJEHtCKEXlAK86pAa0oNaAVpQa0otSAVpQa0MpmLumAHWVpaZ7fxSdXVibPPO+ceaZJnfjbj0ye+f3f9d2TZybJ/Y99dZbc9ThSA1pRakArSg1oRakBrSg1oBWlBrSi1IBWlBrQihF5QCtG5AGt2H4CrRiRB7RiRB7Qiu0n0IoReUArRuQBrRiRB7TinBrQilIDWlFqQCtKDWhFqQGt1BhjtvDlfYfnC2fPuuDA+bPkPv6/T02eOTLPS2B56ZzJM//7E2+bPDNJnvOad0ye+fTxB9e9RtaRGtCKUgNaUWpAK0oNaEWpAa0oNaAVpQa0YpoU0IppUkArtp9AK6ZJAa2YJgW0YvsJtGKaFNCKaVJAK6ZJAa04pwa0otSAVpQa0IpSA1pRakArSg1oZTPXqcGO8sixJ872Es66pZr+eOSK1986eWaSPHrjFbPkrseRGtCKUgNaUWpAK0oNaEWpAa0oNaAVpQa0YkQe0IoReUArtp9AK0bkAa0YkQe0YvsJtGJEHtCKEXlAK0bkAa04pwa0otSAVpQa0IpSA1pRakArNcaYLXx53+H5woFd4djXPjt55rkXft+618g6UgNaUWpAK0oNaEWpAa0oNaAVpQa0otSAVpQa0IoReUArRuQBrZgmBbRimhTQijcKgFaUGtCKEXlAK0bkAa0YkQe04pwa0IpSA1pRakArSg1oRakBvYwxdsR/SW7YDZnWaq17/f7v9LXupCO1G3ZJ5ly51rp71rrX7/9cuZNk7qRSA9g2pQa0spNK7dZdkjlXrrXunrXu9fs/V+4kmbU4QQfQwk46UgPYtme91Krqpqr6ji1835ur6qI51tRVVf3D2V4DTKGqjm72tmfjSO2mJGdUalV1TpI3J1FqZ2CM8cNnew2d1Sq7nR1m1gekqg5W1Seq6vNVdaSq3pHVYvpMVX1mcZtbFoNa7quqd6353geq6u1VdXuSNyS5MsmHq+reqjpwmp97SVXdX1UfrKp/raqPbeXo8BSZR9Z8fnNVvXM7mYuc36yqG9d8/s6q+rXt5i6yNv3bbRNZ76mqt6z5/Deq6lcnyv7FqvrnxWP7/sUvsR2Xuci9pKq+WFW/l+TuJC+cKHOO5+ukmWtyt/Q6ONVjUlVHF8+lz1fVnVX1/MVtL62qf6yqz1XVe85kjXP/lvnJJA+NMS4fY7wsyfuSPJTk2jHGtYvbvHWMcWWSy5L8SFVdtub7vzXGuGaM8aEkdyV54xjj5WOMY5v42S9OcusY47Ik/5PkxtPc/mz5aJLXr/n8+iR/cZbWspE/TPKmJFkcnfx8kg9vN7SqXpLV+/+qMcbLk5xM8sadlvkML07yx2OMV4wxvjxh5tTP1x3zGtjgMTmY5M4xxuVJ/i7JLy2+5XeS3DLGuCrJN87kZ81dav+W5McXRyOvHmM8forbXF9Vdye5J8kPJHnpmq/92TZ+9lfHGHcsPv5Qkmu2kTWbMcY9SS6sqouq6vIkj40xvnK21/VMY4wHkjxSVa9I8hNJ7hljPDJB9I8leWWSz1XVvYvPv2cHZq715THGnRPmJfM8X3fSa2C9x+R4ko8vbvMvSS5ZfPyqJB9ZfPwnZ/KDNvPnvLdsjPHvVfXKJD+d5L1Vddvar1fVpUluTnLVGOOxqvpAkv1rbrKdwaHPvFZlu9eunMi3/xLYv94Nt+BjSa5L8oKsHrntVH+Q1XObL0jyRxNlVpIPjjF+faK8uTLXmmOg7dTP17kyt/o6OOVjUlU3j/+/ruxkvr2TtrTeuc+pXZTkqcX28beTXJHkiSTnL27ynKw+QR5f7KV/aoO4td+3GS+qqqsXH78hye1nsvZTeDirR1QXVNV5SV67zby1PprV7dx1WS24neqvsnpK4aokn5oo89NJrquqC5Okqp5bVRfvwMy5Tf18nStzq6+DM31M7sjqayI5w1MHsx6pJfnBJL9VVStJnk7yy0muTvLXVfX1Mca1VXVPkvuS/GdW78h6PpDk96vqWJKrN3Fe7YtJ3lRV70/ypSS3bOeOjDGerqp3J/mnJP+V5P7t5D0j+76qOj/Jg2OMr0+VO7UxxvHFGzzfHGOcnCjzC1X1tiS3Lc7VPZ3kV5Js+VzVHJnPgkmfr3NlbvV1sMFjsp63JPnTxZtTf3kma2z5Lwqq6pIkH1+8OcFEFk/Gu5P83BjjS2d7PV3M8Xzdy68B19iwKVX10iT/keTTCo2drOWRGrB3OVIDWlFqQCtKDWhFqQGtKDWgFaUGtPJ/CQb8ySKx2M8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2980 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2975 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2985 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2990 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2980 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2975 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2985 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2990 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 3006 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 3006 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 3019 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2994 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 3019 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2994 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2984 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2984 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2949 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 3001 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2949 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 3001 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 3014 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 2979 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 3014 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/home/catlab/anaconda3/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 2979 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def  transliterate_char(sent,attention=False,print_out=True,print_plot=False):\n",
        "  sent = \"\\t\"+sent+\"\\n\"\n",
        "  sent_vec = [seqatt.input_token_index[i] for i in sent]\n",
        "  sent_vec = sequence.pad_sequences([sent_vec],maxlen=seqatt.max_length_x,padding=\"post\")\n",
        "\n",
        "  if attention:\n",
        "      pred,attention = seqatt.evaluate_model(sent_vec[0],True)\n",
        "      if print_out:\n",
        "        print(\"Input:\",sent)\n",
        "        print(\"Output:\",pred)\n",
        "      \n",
        "      if print_plot:\n",
        "        plot_attention(attention[:len(pred),:len(sent)],sent,pred)\n",
        "\n",
        "      return attention[:len(pred),:len(sent)],pred\n",
        "      \n",
        "  else:\n",
        "      pred = seqatt.evaluate_model(sent_vec[0],False)\n",
        "      print(\"Input:\",sent)\n",
        "      print(\"Output:\",pred)\n",
        "        \n",
        "        \n",
        "import seaborn as sb\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import FontProperties as fontp\n",
        "\n",
        "font_new =  fontp(fname='tamil.ttf')\n",
        "font_dict = {'fontsize':10}\n",
        "\n",
        "def plot_attention(attention,actual,pred):\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    img = sb.heatmap(attention,cbar=False)\n",
        "    ax.set_xticklabels(['start']+list(actual[1:-1])+['end'])\n",
        "    ax.set_yticklabels(list(pred),fontdict=font_dict,fontproperties=font_new)\n",
        "    fig.savefig(\"ex.png\")\n",
        "    temp = plt.imread(\"ex.png\")\n",
        "    plot.append(temp)\n",
        "    plt.show()\n",
        "import random\n",
        "\n",
        "idxs = [i for i in range(0,5747)]\n",
        "random.shuffle(idxs)\n",
        "idxs = idxs[:9]\n",
        "plot = []\n",
        "for i in idxs:\n",
        "  input = \"\"\n",
        "  for x in seqatt.encoder_test[i][1:]:\n",
        "    if seqatt.inv_input_token_index[x]==\"\\n\":\n",
        "      break\n",
        "    input += seqatt.inv_input_token_index[x]\n",
        "\n",
        "  att,pred =  transliterate_char(input,attention=True,print_out=False,print_plot=True)\n",
        "\n",
        "\n",
        "wandb.log({\"Attention HeatMaps\": [wandb.Image(img) for img in plot]})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680f15bf",
      "metadata": {
        "id": "680f15bf"
      },
      "outputs": [],
      "source": [
        "#Attention Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25acd0f4",
      "metadata": {
        "id": "25acd0f4"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52f84fc4",
      "metadata": {
        "id": "52f84fc4"
      },
      "outputs": [],
      "source": [
        "def cstr(s,flag=False, color='black'):\n",
        "  if flag: \n",
        "    return \"<text style=color:#000;background-color:{};font-size:31px>{} </text>\".format(color, s)\n",
        "    \n",
        "  return \"<text style=color:#000;background-color:{};font-size:30px>{} </text>\".format(color, s)\n",
        "\t\n",
        "# print html\n",
        "def print_color(t):\n",
        "\tdisplay(html_print(''.join([cstr(ti, color=ci) if ci != '#f42e2e' else cstr(ti,True,color=ci) for ti,ci in t])))\n",
        "\n",
        "# get appropriate color for value\n",
        "def get_clr(value):\n",
        "\tcolors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n",
        "\t\t'#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "\t\t'#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "\t\t'#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "\tvalue = int((value * 100) / 5)\n",
        "\treturn colors[value]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96f5d02d",
      "metadata": {
        "id": "96f5d02d"
      },
      "outputs": [],
      "source": [
        "def visualize_connections(input, attention_matrix, target_char_index):\n",
        "  text_colours = []\n",
        "\n",
        "  for i in range(len(input)+2):\n",
        "    if i == 0:\n",
        "      text = (\"/start/\",get_clr(attention_matrix[target_char_index][i]))\n",
        "    elif i == len(input)+1:\n",
        "      text = (\"/end/\",get_clr(attention_matrix[target_char_index][i]))\n",
        "    else:\n",
        "      text = (input[i-1], get_clr(attention_matrix[target_char_index][i]))\n",
        "    \n",
        "    text_colours.append(text)\n",
        "  print_color(text_colours)\n",
        "\n",
        "def visualize_output(input,idx):\n",
        "  text_colours = []\n",
        "  for i in range(len(input)):\n",
        "    \n",
        "    if i==idx:\n",
        "      text = (input[i],'#f42e2e')\n",
        "    else:\n",
        "      text = (input[i],'#85c2e1')\n",
        "    text_colours.append(text)\n",
        "  print_color(text_colours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf0c2dc",
      "metadata": {
        "id": "2bf0c2dc"
      },
      "outputs": [],
      "source": [
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93c82d23",
      "metadata": {
        "id": "93c82d23"
      },
      "outputs": [],
      "source": [
        "    def  transliterate_attn(sent,attention=False,print_out=True,print_plot=False):\n",
        "      sent = \"\\t\"+sent+\"\\n\"\n",
        "      sent_vec = [seqatt.input_token_index[i] for i in sent]\n",
        "      sent_vec = sequence.pad_sequences([sent_vec],maxlen=seqatt.max_length_x,padding=\"post\")\n",
        "\n",
        "      if attention:\n",
        "          pred,attention = seqatt.evaluate_model(sent_vec[0],True)\n",
        "          if print_out:\n",
        "            print(\"Input:\",sent)\n",
        "            print(\"Output:\",pred)\n",
        "\n",
        "          if print_plot:\n",
        "            attention_plot(attention[:len(pred),:len(sent)],sent,pred)\n",
        "\n",
        "          return attention[:len(pred),:len(sent)],pred\n",
        "\n",
        "      else:\n",
        "          pred = seqatt.evaluate_model(sent_vec[0],False)\n",
        "          print(\"Input:\",sent)\n",
        "          print(\"Output:\",pred) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b605a7",
      "metadata": {
        "id": "88b605a7",
        "outputId": "cd0bde3c-8af5-454f-ce6b-f74d4beb50c5",
        "colab": {
          "referenced_widgets": [
            "cd6761af723a48b29960f8a780ea6235"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd6761af723a48b29960f8a780ea6235",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=2, description='idx', max=5), Output()), _dom_classes=('widget-interact'…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#word to visualisation for connectivity\n",
        "input_word = 'ennachu' #@param {type:\"string\"}\n",
        "attention_matrix,pred = transliterate_attn(input_word,attention=True,print_out=False)\n",
        "\n",
        "def color_code(idx):\n",
        "    print()\n",
        "    visualize_connections(input_word,attention_matrix,idx)\n",
        "    print()\n",
        "    print()\n",
        "    print(pred)\n",
        "    visualize_output(pred,idx)\n",
        "\n",
        "  \n",
        "interact(color_code, idx=(0,len(pred)-1));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21583050",
      "metadata": {
        "id": "21583050"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "RnnWithAttn.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}